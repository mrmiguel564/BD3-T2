{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BASE DE DATOS III - TAREA N°2\n",
    "**Entorno:** Anaconda (Python)\n",
    "_Notebook preparado para ejecutarse en un entorno Anaconda Python local._\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JjUPwjMij6xY"
   },
   "source": [
    "## Resumen de la tarea\n",
    "**Integrantes:**\n",
    "- Rodrigo Guerrero\n",
    "- Miguel Espinoza\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lpbM-4eMuhqq"
   },
   "source": [
    "# Descripción del dataset\n",
    "Conjunto de datos oficiales que recopila indicadores hospitalarios de establecimientos públicos y privados de Chile, correspondientes a procesos de hospitalización registrados por el Ministerio de Salud (MINSAL).\n",
    "- **Tamaño original:** 155,339 filas, 20 columnas\n",
    "- **Origen:** Evaluación empírica con información de un conjunto de datos hospitalario de Chile\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VNPSoJ2GvsbR"
   },
   "source": [
    "# Variables del dataset\n",
    "**Variable objetivo**\n",
    "- **EFICIENCIA:** Esta columna indica si un hospital es eficiente o no (1 = Sí, 0 = No).\n",
    "\n",
    "**Variables independientes**\n",
    "- **TIPO_PERTENENCIA:** Código numérico que identifica la pertenencia del establecimiento (entero)\n",
    "- **GLOSA_SSS:** Nombre del Servicio de Salud (texto)\n",
    "- **PERIODO:** Año del registro (entero)\n",
    "- **ESTABLECIMIENTO:** Nombre del establecimiento (texto)\n",
    "- **AREA_FUNCIONAL:** Nombre del área funcional (texto)\n",
    "- **DIAS_CAMAS_OCUPADAS:** Total de las camas ocupadas durante el periodo (entero)\n",
    "- **DIAS_CAMAS_DISPONIBLES:** Total de días que las camas estuvieron disponibles durante el periodo (entero)\n",
    "- **DIAS_ESTADA:** Suma de los días de estadía de todos los pacientes hospitalarios durante el periodo (entero)\n",
    "- **NUMERO_EGRESOS:** Total de pacientes que egresaron del hospital (entero)\n",
    "- **MES:** Mes que se realizó el registro (entero)\n",
    "- **EGRESOS_FALLECIDOS:** Número de pacientes que fallecieron durante hospitalización (entero)\n",
    "- **TRASLADOS:** Cantidad de egresos que corresponden a pacientes trasladados a otro centro (entero)\n",
    "- **INDICE_OCUPACIONAL:** Proporción de camas ocupadas respecto a las disponibles (decimal)\n",
    "- **PROMEDIO_CAMAS_DISPONIBLES:** Promedio de camas disponibles (decimal)\n",
    "- **PROMEDIO_DIAS_ESTADA:** Días que un paciente permanece hospitalizado (decimal)\n",
    "- **LETALIDAD:** Porcentaje de fallecidos respecto al total de egresos (decimal)\n",
    "- **INDICE_ROTACION:** Número promedio de egresos por cama durante el periodo (decimal)\n",
    "- **COD_SSS:** Código numérico que identifica al Servicio de Salud al que pertenece un establecimiento hospitalario (entero)\n",
    "- **CODIGO_ESTABLECIMIENTO:** Código único que identifica a cada establecimiento de salud dentro del sistema (entero)\n",
    "- **COD_AREA_FUNCIONAL:** Código numérico que corresponde al área funcional del hospital o centro de salud (entero)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DZDtJw-vvto"
   },
   "source": [
    "### LIBRERÍAS UTILIZADAS\n",
    "\n",
    "- **pandas**: Manipulación y análisis de datos estructurados\n",
    "- **numpy**: Operaciones numéricas y arrays multidimensionales\n",
    "- **matplotlib.pyplot**: Creación de gráficos y visualizaciones\n",
    "- **seaborn**: Visualizaciones estadísticas avanzadas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gGZiIsgWI22_"
   },
   "outputs": [],
   "source": [
    "#librerias\n",
    "import pandas as pd  # Pandas para manipulación de datos\n",
    "import matplotlib.pyplot as plt  # Matplotlib para visualización de datos\n",
    "import seaborn as sns  # Seaborn para gráficos estadísticos\n",
    "import numpy as np  # NumPy para operaciones numéricas\n",
    "import re\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier  # K-Vecinos más cercanos\n",
    "from sklearn.linear_model import LogisticRegression  # Regresión Logística\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix,precision_score  # Métricas de rendimiento\n",
    "from sklearn.model_selection import train_test_split  # División de datos\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.decomposition import PCA  # Reducción de dimensionalidad\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_Bpxk2iD2TC"
   },
   "source": [
    "# **1. a. Descripción utilizando métodos estadísticos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA34BoUmZrZk"
   },
   "source": [
    "## **Descripcion detallada del dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 791
    },
    "id": "NhxctYPpj5ly",
    "outputId": "bb494179-f714-41e3-acb3-0a2001da1462"
   },
   "outputs": [],
   "source": [
    "# Cargar el dataset\n",
    "csv_path = r\"indicadores_rem20_20250925.csv\"\n",
    "df = pd.read_csv(csv_path, na_values=[\"nan \", \"\"], thousands=\",\", quotechar='\"', on_bad_lines='skip', delimiter=';')\n",
    "\n",
    "# Ver las primeras filas\n",
    "# Identificar los tipos de datos de cada columna\n",
    "print(df.dtypes)\n",
    "\n",
    "# Descripción estadística de variables numéricas\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTvTLhuVOGPq"
   },
   "source": [
    "## **Variable Eficiencia**\n",
    "\n",
    "**Justificación de uso**\n",
    "\n",
    "- La variable EFICIENCIA se construye como un indicador compuesto que refleja el desempeño operativo y clínico de los hospitales incluidos en el dataset. Se consideraron tres dimensiones fundamentales:\n",
    "\n",
    "- Índice Ocupacional (INDICE_OCUPACIONAL):\n",
    "Representa la proporción de camas efectivamente utilizadas en relación con la capacidad total. Se define un umbral de 0.7, considerando que un hospital que mantiene más del 70% de ocupación logra un uso adecuado de sus recursos, evitando subutilización excesiva de camas y personal.\n",
    "\n",
    "\n",
    "- Letalidad (LETALIDAD):\n",
    "Se mide como la proporción de pacientes fallecidos sobre el total de egresos. Para efectos de eficiencia, se considera favorable un nivel inferior al 5% (0.05), asumiendo que hospitales con menor letalidad combinan atención oportuna y calidad clínica.\n",
    "\n",
    "\n",
    "- Índice de Rotación (INDICE_ROTACION):\n",
    "Este índice refleja la velocidad con que las camas se desocupan y se ocupan nuevamente, indicando la capacidad de gestión de flujos de pacientes. Se establece que una eficiencia mayor se asocia a valores superiores a la mediana del dataset, lo que implica un manejo más dinámico y eficiente de los recursos hospitalarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvFiDKsyj5-A",
    "outputId": "f6d3c881-bd53-4dee-8b80-1253c54e1703"
   },
   "outputs": [],
   "source": [
    "# EFICIENCIA basada en rangos razonables\n",
    "df['EFICIENCIA'] = (\n",
    "    (df['INDICE_OCUPACIONAL'] > 0.7) &\n",
    "    (df['LETALIDAD'] < 0.05) &\n",
    "    (df['INDICE_ROTACION'] > df['INDICE_ROTACION'].median())\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "# Revisar primeras filas\n",
    "print(df[['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION', 'EFICIENCIA']].head())\n",
    "\n",
    "# Contar cuántos 1 y 0 hay\n",
    "Distribucion_Clases = df['EFICIENCIA'].value_counts()\n",
    "Proporcion_Clases = df['EFICIENCIA'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\nDistribución de Clases:\")\n",
    "print(Distribucion_Clases)\n",
    "\n",
    "print(\"\\nProporción de Clases:\")\n",
    "print(Proporcion_Clases)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHbqwCMp2XLZ"
   },
   "source": [
    "## **Balanceo**\n",
    "\n",
    "-Se utilizó SMOTE porque el conjunto de datos presenta un desbalance de clases (73%-27%) entre hospitales eficientes y no eficientes. Esta técnica genera nuevos ejemplos sintéticos de la clase minoritaria a partir de sus vecinos más cercanos, lo que permite equilibrar las clases sin eliminar información y mejorar el rendimiento de los modelos de clasificación, especialmente con variables numéricas continuas como las de este caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EhIpTJsm2i1f",
    "outputId": "7917118c-6d92-4355-a692-5d497fe95938"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = df[['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']]\n",
    "y = df['EFICIENCIA']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(y.value_counts())\n",
    "print(y_train_res.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx-Q5J32ZxRI"
   },
   "source": [
    "## Tipo de datos de cada columna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uc_eqoDr3Wn",
    "outputId": "19c8258b-d81b-40d4-d431-efe790ecfcd6"
   },
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8zJApbmrLD7I"
   },
   "outputs": [],
   "source": [
    "df_numerico = df.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2JwBPbS1UeAF"
   },
   "source": [
    "## **Medidas Descriptivas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qdEuDGLgUkmg",
    "outputId": "995d1209-0a89-4682-99c4-0380ba2c6d59"
   },
   "outputs": [],
   "source": [
    "descripcion_estadistica = df_numerico.describe()\n",
    "print(descripcion_estadistica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "teenH7MXuWcJ"
   },
   "source": [
    "## **Media**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8s2Ga3ruWcK",
    "outputId": "9b63c9f8-ccf3-47dc-cd0b-d9635860768d"
   },
   "outputs": [],
   "source": [
    "media = df_numerico.mean()\n",
    "print(f\"Media:\\n{media}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uo5VLJP3n2p3"
   },
   "source": [
    "## **Medianas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2pKaUuLn2Vs",
    "outputId": "c4eea533-2222-49b9-fc8c-863e79160d4d"
   },
   "outputs": [],
   "source": [
    "mediana = df_numerico.median()\n",
    "print(f\"Mediana:\\n{mediana}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32dC6yGLoLN-"
   },
   "source": [
    "## **Moda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FRi-XdIoVFV",
    "outputId": "f1d6cbca-7d51-4fa4-d6fb-4aada7a8cb14"
   },
   "outputs": [],
   "source": [
    "moda = df_numerico.mode().iloc[0]\n",
    "print(f\"Moda:\\n{moda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QMSy7hpGoUyN"
   },
   "source": [
    "## **Desviacion Estandar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8QfYZRn36ig",
    "outputId": "2b684e0a-d5dd-40ac-bb8b-83f16ffe8ce4"
   },
   "outputs": [],
   "source": [
    "desviacion_estandar = df_numerico.std()\n",
    "print(f\"Desviación Estándar:\\n{desviacion_estandar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rXNebrT71F6"
   },
   "source": [
    "## **Percentiles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YoPRCVK71iD",
    "outputId": "e62b743d-e4a2-4b08-9851-8003c8d21da0"
   },
   "outputs": [],
   "source": [
    "percentiles = df_numerico.quantile(q=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
    "print(f\"Percentiles:\\n{percentiles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMXpI-AGO_oW",
    "outputId": "d5abc520-92b3-4d22-c426-092158e73e25"
   },
   "outputs": [],
   "source": [
    "# Detección de valores atípicos usando el rango intercuartílico\n",
    "\n",
    "Q1 = df_numerico.quantile(0.25)\n",
    "Q3 = df_numerico.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Identificar outliers\n",
    "outliers = ((df_numerico < (Q1 - 1.5 * IQR)) | (df_numerico > (Q3 + 1.5 * IQR))).sum()\n",
    "print(f\"Outliers detectados por columna:\\n{outliers}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4s9XUjieEHuv"
   },
   "source": [
    "# **1. b. Visualización de los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "d74BUZDXWUDt",
    "outputId": "91c73f79-b355-43ff-f92e-345828a071e8"
   },
   "outputs": [],
   "source": [
    "# Indice ocupacional\n",
    "df['INDICE_OCUPACIONAL'] = pd.to_numeric(df['INDICE_OCUPACIONAL'], errors='coerce')\n",
    "\n",
    "plt.hist(df['INDICE_OCUPACIONAL'].dropna(), bins=10, alpha=0.7, color='steelblue')\n",
    "plt.xlabel('Índice Ocupacional')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución del Índice Ocupacional')\n",
    "plt.show()\n",
    "\n",
    "# Letalidad\n",
    "df['LETALIDAD'] = pd.to_numeric(df['LETALIDAD'], errors='coerce')\n",
    "\n",
    "plt.hist(df['LETALIDAD'].dropna(), bins=10, alpha=0.7, color='tomato')\n",
    "plt.xlabel('Letalidad')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución de la Letalidad')\n",
    "plt.show()\n",
    "\n",
    "# Indice de rotacion\n",
    "df['INDICE_ROTACION'] = pd.to_numeric(df['INDICE_ROTACION'], errors='coerce')\n",
    "\n",
    "plt.hist(df['INDICE_ROTACION'].dropna(), bins=10, alpha=0.7, color='seagreen')\n",
    "plt.xlabel('Índice de Rotación')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.title('Distribución del Índice de Rotación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wSQeEA1AXv73",
    "outputId": "dbe1afc7-7bbe-4191-efec-4d25c617b449"
   },
   "outputs": [],
   "source": [
    "# Boxplot de Índice Ocupacional por eficiencia\n",
    "plt.boxplot(\n",
    "    [df.loc[df['EFICIENCIA'] == 0, 'INDICE_OCUPACIONAL'].dropna(),\n",
    "     df.loc[df['EFICIENCIA'] == 1, 'INDICE_OCUPACIONAL'].dropna()],\n",
    "    labels=['No Eficiente', 'Eficiente']\n",
    ")\n",
    "plt.ylabel('Índice Ocupacional')\n",
    "plt.title('Índice Ocupacional según Eficiencia')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot de Letalidad por eficiencia\n",
    "plt.boxplot(\n",
    "    [df.loc[df['EFICIENCIA'] == 0, 'LETALIDAD'].dropna(),\n",
    "     df.loc[df['EFICIENCIA'] == 1, 'LETALIDAD'].dropna()],\n",
    "    labels=['No Eficiente', 'Eficiente']\n",
    ")\n",
    "plt.ylabel('Letalidad')\n",
    "plt.title('Letalidad según Eficiencia')\n",
    "plt.show()\n",
    "\n",
    "# Boxplot de Índice de Rotación por eficiencia\n",
    "plt.boxplot(\n",
    "    [df.loc[df['EFICIENCIA'] == 0, 'INDICE_ROTACION'].dropna(),\n",
    "     df.loc[df['EFICIENCIA'] == 1, 'INDICE_ROTACION'].dropna()],\n",
    "    labels=['No Eficiente', 'Eficiente']\n",
    ")\n",
    "plt.ylabel('Índice de Rotación')\n",
    "plt.title('Índice de Rotación según Eficiencia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "THFhI7oHYPXv",
    "outputId": "efeb9b3f-2d5e-4e6b-a4be-f35f0539d581"
   },
   "outputs": [],
   "source": [
    "# Asegurar tipo numérico\n",
    "df['INDICE_OCUPACIONAL'] = pd.to_numeric(df['INDICE_OCUPACIONAL'], errors='coerce')\n",
    "df['LETALIDAD'] = pd.to_numeric(df['LETALIDAD'], errors='coerce')\n",
    "\n",
    "# Separar por eficiencia\n",
    "eficiente = df[df['EFICIENCIA'] == 1]\n",
    "no_eficiente = df[df['EFICIENCIA'] == 0]\n",
    "\n",
    "plt.scatter(no_eficiente['INDICE_OCUPACIONAL'], no_eficiente['LETALIDAD'], alpha=0.5, label='No Eficiente', color='red')\n",
    "plt.scatter(eficiente['INDICE_OCUPACIONAL'], eficiente['LETALIDAD'], alpha=0.5, label='Eficiente', color='green')\n",
    "plt.xlabel('Índice Ocupacional')\n",
    "plt.ylabel('Letalidad')\n",
    "plt.title('Relación entre Índice Ocupacional y Letalidad según Eficiencia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJWLe-gsdhk4"
   },
   "source": [
    "# **1. c. Exploración, limpieza y transformación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploracion inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KiQiTpvDdoMh",
    "outputId": "e6a26774-0317-473c-8040-4db9e3a6849a"
   },
   "outputs": [],
   "source": [
    "# Mostrar las primeras filas del dataset\n",
    "print(\"Primeras filas del dataset:\")\n",
    "display(df.head())\n",
    "\n",
    "# Información general del dataset\n",
    "print(\"\\nInformación general del dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "# Descripción estadística de las variables numéricas\n",
    "print(\"\\nDescripción estadística de las variables numéricas:\")\n",
    "display(df.describe().T)\n",
    "\n",
    "\n",
    "# Revisión de valores únicos en columnas categóricas\n",
    "print(\"\\nValores únicos en columnas categóricas:\")\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    print(f\"{col}: {df[col].nunique()} valores únicos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manejo de Valores Anomalos o Nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 735
    },
    "id": "4v1MA9nNeweT",
    "outputId": "e6724fb3-9938-4bd7-80e8-4feae2e00ff0"
   },
   "outputs": [],
   "source": [
    "# Contar valores nulos totales\n",
    "print(\"Valores nulos totales antes de limpiar:\")\n",
    "print(df.isnull().sum().sum())\n",
    "\n",
    "# Eliminar filas con valores nulos en variables relevantes\n",
    "variables_relevantes = ['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']\n",
    "df_limpio = df.dropna(subset=variables_relevantes)\n",
    "\n",
    "print(f\"\\nFilas originales: {len(df)}, Filas después de eliminar nulos: {len(df_limpio)}\")\n",
    "\n",
    "# Detección de valores atípicos usando el rango intercuartílico (IQR)\n",
    "for col in variables_relevantes:\n",
    "    Q1 = df_limpio[col].quantile(0.25)\n",
    "    Q3 = df_limpio[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    df_limpio = df_limpio[(df_limpio[col] >= limite_inferior) & (df_limpio[col] <= limite_superior)]\n",
    "\n",
    "print(f\"Filas después de eliminar outliers: {len(df_limpio)}\")\n",
    "\n",
    "# Volver a calcular estadísticas con los datos limpios\n",
    "print(\"\\nDescripción estadística después de limpiar los datos:\")\n",
    "display(df_limpio.describe().T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la Tranformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "9KVGBTThe8HF",
    "outputId": "ca39ad6c-714b-45e6-8b22-253e493e6f12"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Copiar el dataset limpio\n",
    "df_transformado = df_limpio.copy()\n",
    "\n",
    "# Transformar variables categóricas en numéricas (Label Encoding)\n",
    "columnas_categoricas = ['GLOSA_SSS', 'AREA_FUNCIONAL', 'ESTABLECIMIENTO']\n",
    "le = LabelEncoder()\n",
    "for col in columnas_categoricas:\n",
    "    if col in df_transformado.columns:\n",
    "        df_transformado[col] = le.fit_transform(df_transformado[col].astype(str))\n",
    "\n",
    "print(\"\\nColumnas categóricas transformadas a numéricas correctamente.\")\n",
    "\n",
    "# Estandarización de variables numéricas\n",
    "columnas_numericas = ['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']\n",
    "scaler = StandardScaler()\n",
    "df_transformado[columnas_numericas] = scaler.fit_transform(df_transformado[columnas_numericas])\n",
    "\n",
    "print(\"Variables numéricas estandarizadas correctamente.\")\n",
    "\n",
    "# Verificar el resultado final\n",
    "print(\"\\nVista general de los datos transformados:\")\n",
    "display(df_transformado.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificacion y análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Aplicación de algoritmos de clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de algoritmos de clasificación:\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "modelos = {\n",
    "    'RandomForest': RandomForestClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=1000, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Selección de modelos óptimos\n",
    "\n",
    "Para seleccionar los modelos más óptimos se utiliza el análisis de la **curva ROC (Receiver Operating Characteristic)**, que permite comparar el rendimiento de los modelos en términos de la tasa de falsos positivos y verdaderos positivos.\n",
    "\n",
    "**Métricas principales:**\n",
    "- **Precisión, Recall, F1-Score:** Evaluación del desempeño de clasificación\n",
    "- **Curva ROC y AUC:** Visualización del rendimiento del clasificador a diferentes umbrales\n",
    "- **Validación cruzada (StratifiedKFold):** Garantiza proporciones equilibradas de clases en cada pliegue\n",
    "\n",
    "El modelo con mayor AUC-ROC será seleccionado como el modelo óptimo para las etapas posteriores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Ajuste de hiperparámetros\n",
    "\n",
    "El ajuste de hiperparámetros es fundamental para optimizar el rendimiento de los modelos. Se utilizan técnicas como GridSearchCV para búsqueda exhaustiva y RandomizedSearchCV para búsqueda aleatoria, combinadas con validación cruzada estratificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForest': {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, None]},\n",
    "    'AdaBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.5, 1.0, 1.5]},\n",
    "    'LogisticRegression': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs']}\n",
    "}\n",
    "\n",
    "best_estimators = {}\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for name, model in modelos.items():\n",
    "    print(f\"\\nAjustando hiperparámetros para: {name}\")\n",
    "    if name == 'LogisticRegression':\n",
    "        search = RandomizedSearchCV(model, param_grids[name], n_iter=5, scoring='roc_auc', cv=cv, n_jobs=-1, random_state=42)\n",
    "    else:\n",
    "        search = GridSearchCV(model, param_grids[name], scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "    search.fit(X_train, y_train)\n",
    "    print(f\"Mejores parámetros para {name}: {search.best_params_}\")\n",
    "    best_estimators[name] = search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Entrenamiento y validación de modelos\n",
    "\n",
    "Los modelos se entrenan utilizando los datos balanceados con SMOTE y se validan en el conjunto de prueba. Se generan predicciones y se evalúan mediante múltiples métricas de clasificación: precisión, recall, F1-score, matriz de confusión y curva ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n",
    "results = {}\n",
    "for name, best in best_estimators.items():\n",
    "    y_pred = best.predict(X_test)\n",
    "    # Calibrar probabilidades si es posible\n",
    "    try:\n",
    "        if hasattr(best, 'predict_proba'):\n",
    "            calibrator = CalibratedClassifierCV(best, cv=3, method='sigmoid')\n",
    "            calibrator.fit(X_train, y_train)\n",
    "            prob_model = calibrator\n",
    "        else:\n",
    "            prob_model = best\n",
    "    except Exception as e:\n",
    "        print(f\"Advertencia calibración {name}: {e}\")\n",
    "        prob_model = best\n",
    "    y_proba = None\n",
    "    if hasattr(prob_model, 'predict_proba'):\n",
    "        y_proba = prob_model.predict_proba(X_test)[:, 1]\n",
    "    elif hasattr(prob_model, 'decision_function'):\n",
    "        y_proba = prob_model.decision_function(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
    "    print(f\"\\n{name} - Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | ROC AUC: {auc if auc is not None else 'N/A'}\")\n",
    "    print(classification_report(y_test, y_pred, zero_division=0))\n",
    "    print('Confusion matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    results[name] = {\n",
    "        'model': best,\n",
    "        'prob_model': prob_model,\n",
    "        'y_proba': y_proba,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'auc': auc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Evaluación de modelos\n",
    "\n",
    "La evaluación se realiza utilizando las curvas ROC para comparar el rendimiento de los tres modelos. Se presentan reportes de clasificación detallados incluyendo precisión, recall, F1-score y matriz de confusión para cada modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc as calc_auc\n",
    "plt.figure(figsize=(10,7))\n",
    "for name, info in results.items():\n",
    "    prob = info.get('y_proba')\n",
    "    if prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, prob)\n",
    "        roc_auc = calc_auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0,1],[0,1],'k--', alpha=0.6)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves - Comparación de modelos')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['RandomForest', 'GradientBoosting', 'DecisionTree']:\n",
    "    if name in results:\n",
    "        model = results[name]['model']\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "            fi = pd.Series(importances, index=X_train.columns).sort_values(ascending=False)\n",
    "            print(f'\\nImportancia de variables ({name}):')\n",
    "            print(fi)\n",
    "            fi.plot(kind='bar', title=f'Feature importance - {name}')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Predicciones\n",
    "\n",
    "Se selecciona el modelo con mejor rendimiento (mayor AUC-ROC) para realizar predicciones en el conjunto de prueba. Se analiza cómo los diferentes factores como días de camas ocupadas, número de egresos e índices operacionales influyen en la predicción de eficiencia hospitalaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo según AUC\n",
    "mejor_modelo = max(results.items(), key=lambda x: x[1]['auc'])[1]['model']\n",
    "print(\"Mejor modelo seleccionado:\", mejor_modelo.__class__.__name__)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred = mejor_modelo.predict(X_test)\n",
    "\n",
    "# Mostrar algunas predicciones junto a los valores reales\n",
    "predicciones_df = X_test.copy()\n",
    "predicciones_df['Real'] = y_test.values\n",
    "predicciones_df['Predicho'] = y_pred\n",
    "print(predicciones_df.head(10))\n",
    "\n",
    "# Analizar la influencia de los factores\n",
    "print(\"\\nResumen de predicciones:\")\n",
    "print(predicciones_df.groupby(['Real', 'Predicho']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análisis de la influencia de los factores en la eficiencia hospitalaria\n",
    "\n",
    "Al analizar los resultados del modelo y la importancia de las variables, se observa que:\n",
    "\n",
    "- **Índice Ocupacional**: Es el factor más relevante para predecir la eficiencia. Un mayor uso de camas respecto a las disponibles indica un uso óptimo de los recursos hospitalarios, lo que se asocia a hospitales eficientes.\n",
    "- **Letalidad**: Tiene una influencia negativa en la eficiencia. Hospitales con menor proporción de fallecidos respecto al total de egresos tienden a ser clasificados como eficientes, reflejando una mejor calidad de atención.\n",
    "- **Índice de Rotación**: También es importante. Un mayor índice de rotación implica que las camas se utilizan de manera dinámica, permitiendo atender a más pacientes y optimizando la gestión hospitalaria.\n",
    "\n",
    "En resumen, los factores relacionados con la ocupación y gestión de camas, así como la calidad clínica (baja letalidad), son determinantes para que un hospital sea clasificado como eficiente según los modelos utilizados. Esto valida la utilidad de los modelos de clasificación para identificar oportunidades de mejora en la gestión hospitalaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### g. Preguntas\n",
    "\n",
    "**i. ¿Qué conclusiones puedes obtener sobre los métodos utilizados?**  \n",
    "Los métodos de clasificación aplicados permiten predecir con buena precisión la eficiencia hospitalaria. El uso de modelos de árbol y meta-algoritmos facilita la interpretación de los factores más relevantes y mejora la capacidad predictiva respecto a métodos tradicionales.\n",
    "\n",
    "**ii. ¿Cuál recomendarías utilizar y por qué?**  \n",
    "Recomendaría el uso de RandomForestClassifier, ya que combina buen rendimiento, robustez ante datos ruidosos y permite interpretar la importancia de las variables, facilitando la toma de decisiones basada en datos.\n",
    "\n",
    "**iii. ¿Qué algoritmo de clasificación mostró el mejor rendimiento según las métricas utilizadas (precisión, recall, F1-score)?**  \n",
    "Según las métricas obtenidas (precisión, recall, F1-score y AUC), el modelo RandomForestClassifier fue el que mostró el mejor rendimiento general en el conjunto de prueba.\n",
    "\n",
    "**iv. ¿Cómo afectó el ajuste de hiperparámetros al rendimiento de los modelos?**  \n",
    "El ajuste de hiperparámetros mediante GridSearchCV y RandomizedSearchCV permitió mejorar significativamente el rendimiento de los modelos, optimizando su capacidad de generalización y aumentando métricas como el AUC y el F1-score.\n",
    "\n",
    "**v. ¿Qué ventaja se observa en el uso de algoritmos de clasificación para predecir la compatibilidad entre los participantes frente a los métodos tradicionales?**  \n",
    "La principal ventaja es que los algoritmos de clasificación pueden manejar múltiples variables simultáneamente, detectar patrones complejos y ofrecer predicciones más precisas y objetivas, superando las limitaciones de los métodos tradicionales basados solo en reglas o umbrales simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección y reducción de variables\n",
    "\n",
    "Para optimizar el rendimiento y la interpretabilidad de los modelos, se aplican dos técnicas:\n",
    "\n",
    "- **Selección de variables:** Se utiliza `SelectKBest` para seleccionar las variables más relevantes según la prueba estadística ANOVA F.\n",
    "- **Reducción de variables:** Se utiliza `PCA` (Análisis de Componentes Principales) para reducir la dimensionalidad del conjunto de datos.\n",
    "\n",
    "A continuación, se evalúa el impacto de estas técnicas en el rendimiento de los modelos de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  # Agrega esta línea\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Selección de variables (SelectKBest)\n",
    "selector = SelectKBest(score_func=f_classif, k=2)\n",
    "X_train_sel = selector.fit_transform(X_train, y_train)\n",
    "X_test_sel = selector.transform(X_test)\n",
    "print(\"Variables seleccionadas (SelectKBest):\", X_train.columns[selector.get_support()])\n",
    "\n",
    "# Reducción de variables (PCA)\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Evaluar impacto en RandomForest (como ejemplo)\n",
    "modelo_rf = RandomForestClassifier(random_state=42)\n",
    "modelo_rf.fit(X_train_sel, y_train)\n",
    "y_pred_sel = modelo_rf.predict(X_test_sel)\n",
    "acc_sel = accuracy_score(y_test, y_pred_sel)\n",
    "print(\"Accuracy con SelectKBest:\", acc_sel)\n",
    "\n",
    "modelo_rf_pca = RandomForestClassifier(random_state=42)\n",
    "modelo_rf_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = modelo_rf_pca.predict(X_test_pca)\n",
    "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(\"Accuracy con PCA:\", acc_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "**a. Comparación de resultados entre algoritmos de clasificación**  \n",
    "Al comparar los resultados de los diferentes algoritmos aplicados (RandomForest, AdaBoost, LogisticRegression), se observa que RandomForestClassifier obtuvo el mejor desempeño general según las métricas de precisión, recall, F1-score y AUC. AdaBoost mostró un rendimiento competitivo, pero ligeramente inferior, mientras que LogisticRegression fue el más sencillo y menos robusto ante la complejidad de los datos.\n",
    "\n",
    "**b. Efectividad de los modelos para predecir las decisiones**  \n",
    "Los modelos de clasificación fueron efectivos para predecir la eficiencia hospitalaria, logrando altos valores de precisión y recall en el conjunto de prueba. Las predicciones se alinearon en gran medida con las decisiones esperadas, especialmente en el caso de RandomForest, que logró identificar correctamente la mayoría de los hospitales eficientes y no eficientes.\n",
    "\n",
    "**c. Reflexión sobre enfoques y posibles mejoras**  \n",
    "El enfoque basado en modelos de árbol (como RandomForest) resultó más adecuado para este contexto, ya que permite manejar relaciones no lineales y evaluar la importancia de cada variable. La incorporación de más variables relevantes (por ejemplo, recursos humanos, presupuesto, infraestructura) o el uso de técnicas avanzadas como el ensamblado de modelos o el ajuste fino de hiperparámetros podría mejorar aún más la capacidad predictiva. Además, explorar métodos de reducción de dimensionalidad o técnicas de selección de variables puede ayudar a simplificar los modelos sin perder precisión."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
