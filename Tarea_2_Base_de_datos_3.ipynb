{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Entorno:** Anaconda (Python)\n",
        "\n",
        "_Notebook preparado para ejecutarse en un entorno Anaconda Python local._\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjUPwjMij6xY"
      },
      "source": [
        "**BASE DE DATOS III - TAREA N°2**\n",
        "\n",
        "*Resumen de la tarea*\n",
        "\n",
        "**Integrantes:**\n",
        "- Rodrigo Guerrero\n",
        "- Miguel Espinoza\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpbM-4eMuhqq"
      },
      "source": [
        "# **DESCRIPCIÓN DEL DATASET**\n",
        "\n",
        "Conjunto de datos oficiales que recopila indicadores hospitalarios de establecimientos públicos y privados de Chile, correspondientes a procesos de hospitalización registrados por el Ministerio de Salud (MINSAL).\n",
        "- **Tamaño original**: 155339 filas, 20 columnas\n",
        "- **Origen**: Evaluación empírica con información de un conjunto de datos hospitalario de Chile\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNPSoJ2GvsbR"
      },
      "source": [
        "# ***VARIABLES DEL DATASET***\n",
        "\n",
        "**Variable objetivo**\n",
        "- EFICIENCIA: Esta columna indica si un hospital es eficiente o no (1 = Sí, 0 = No).\n",
        "\n",
        "\n",
        "**Variables independientes**\n",
        "- TIPO_PERTENENCIA: Código numérico que identifica la pertenencia del establecimiento (tipo de dato: Entero)\n",
        "\n",
        "- GLOSA_SSS: Nombre del Servicio de Salud (tipo de dato: Texto)\n",
        "\n",
        "- PERIODO: Año del registro (tipo de dato: Entero)\n",
        "\n",
        "- ESTABLECIMIENTO: Nombre del establecimiento (tipo de dato: Texto)\n",
        "\n",
        "- AREA_FUNCIONAL: Nombre del área funcional (tipo de dato: Texto)\n",
        "\n",
        "- DIAS_CAMAS_OCUPADAS: Total de las camas ocupadas durante el periodo (tipo de dato: Entero)\n",
        "\n",
        "- DIAS_CAMAS_DISPONIBLES: Total de días que las camas estuvieron disponibles durante el periodo (tipo de dato: Entero)\n",
        "\n",
        "- DIAS_ESTADA: Suma de los días de estadía de todos los pacientes hospitalarios durante el periodo (tipo de dato: Entero)\n",
        "\n",
        "- NUMERO_EGRESOS: Total de pacientes que egresaron del hospital (tipo de dato: Entero)\n",
        "\n",
        "- MES: Mes que se realizó el registro (tipo de dato: Entero)\n",
        "\n",
        "- EGRESOS_FALLECIDOS: Número de pacientes que fallecieron durante hospitalización (tipo de dato: Entero)\n",
        "\n",
        "- TRASLADOS: Cantidad de egresos que corresponden a pacientes trasladados a otro centro (tipo de dato: Entero)\n",
        "\n",
        "- INDICE_OCUPACIONAL: Proporción de camas ocupadas respecto a las disponibles (tipo de dato: Decimal)\n",
        "\n",
        "- PROMEDIO_CAMAS_DISPONIBLES: Promedio de camas disponibles (tipo de dato: Decimal)\n",
        "\n",
        "- PROMEDIO_DIAS_ESTADA: Días que un paciente permanece hospitalizado (tipo de dato: Decimal)\n",
        "\n",
        "- LETALIDAD: Porcentaje de fallecidos respecto al total de egresos (tipo de dato: Decimal)\n",
        "\n",
        "- INDICE_ROTACION: Número promedio de egresos por cama durante el periodo (tipo de dato: Decimal)\n",
        "\n",
        "- COD_SSS: Código numérico que identifica al Servicio de Salud al que pertenece un establecimiento hospitalario (tipo de dato: Entero)\n",
        "\n",
        "- CODIGO_ESTABLECIMIENTO: Código único que identifica a cada establecimiento de salud dentro del sistema (tipo de dato: Entero)\n",
        "\n",
        "- COD_AREA_FUNCIONAL: Código numérico que corresponde al área funcional del hospital o centro de salud (tipo de dato: Entero)\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZDtJw-vvto"
      },
      "source": [
        "### LIBRERÍAS UTILIZADAS\n",
        "\n",
        "- **pandas**: Manipulación y análisis de datos estructurados\n",
        "- **numpy**: Operaciones numéricas y arrays multidimensionales\n",
        "- **matplotlib.pyplot**: Creación de gráficos y visualizaciones\n",
        "- **seaborn**: Visualizaciones estadísticas avanzadas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGZiIsgWI22_"
      },
      "outputs": [],
      "source": [
        "#librerias\n",
        "import pandas as pd  # Pandas para manipulación de datos\n",
        "import matplotlib.pyplot as plt  # Matplotlib para visualización de datos\n",
        "import seaborn as sns  # Seaborn para gráficos estadísticos\n",
        "import numpy as np  # NumPy para operaciones numéricas\n",
        "import re\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier  # K-Vecinos más cercanos\n",
        "from sklearn.linear_model import LogisticRegression  # Regresión Logística\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix,precision_score  # Métricas de rendimiento\n",
        "from sklearn.model_selection import train_test_split  # División de datos\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.decomposition import PCA  # Reducción de dimensionalidad\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Bpxk2iD2TC"
      },
      "source": [
        "# **1. a. Descripción utilizando métodos estadísticos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA34BoUmZrZk"
      },
      "source": [
        "## **Descripcion detallada del dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        },
        "id": "NhxctYPpj5ly",
        "outputId": "bb494179-f714-41e3-acb3-0a2001da1462"
      },
      "outputs": [],
      "source": [
        "# Cargar el dataset\n",
        "csv_path = r\"indicadores_rem20_20250925.csv\"\n",
        "df = pd.read_csv(csv_path, na_values=[\"nan \", \"\"], thousands=\",\", quotechar='\"', on_bad_lines='skip', delimiter=';')\n",
        "\n",
        "# Ver las primeras filas\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTvTLhuVOGPq"
      },
      "source": [
        "## **Variable Eficiencia**\n",
        "\n",
        "**Justificación de uso**\n",
        "\n",
        "- La variable EFICIENCIA se construye como un indicador compuesto que refleja el desempeño operativo y clínico de los hospitales incluidos en el dataset. Se consideraron tres dimensiones fundamentales:\n",
        "\n",
        "- Índice Ocupacional (INDICE_OCUPACIONAL):\n",
        "Representa la proporción de camas efectivamente utilizadas en relación con la capacidad total. Se define un umbral de 0.7, considerando que un hospital que mantiene más del 70% de ocupación logra un uso adecuado de sus recursos, evitando subutilización excesiva de camas y personal.\n",
        "\n",
        "\n",
        "- Letalidad (LETALIDAD):\n",
        "Se mide como la proporción de pacientes fallecidos sobre el total de egresos. Para efectos de eficiencia, se considera favorable un nivel inferior al 5% (0.05), asumiendo que hospitales con menor letalidad combinan atención oportuna y calidad clínica.\n",
        "\n",
        "\n",
        "- Índice de Rotación (INDICE_ROTACION):\n",
        "Este índice refleja la velocidad con que las camas se desocupan y se ocupan nuevamente, indicando la capacidad de gestión de flujos de pacientes. Se establece que una eficiencia mayor se asocia a valores superiores a la mediana del dataset, lo que implica un manejo más dinámico y eficiente de los recursos hospitalarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvFiDKsyj5-A",
        "outputId": "f6d3c881-bd53-4dee-8b80-1253c54e1703"
      },
      "outputs": [],
      "source": [
        "# EFICIENCIA basada en rangos razonables\n",
        "df['EFICIENCIA'] = (\n",
        "    (df['INDICE_OCUPACIONAL'] > 0.7) &\n",
        "    (df['LETALIDAD'] < 0.05) &\n",
        "    (df['INDICE_ROTACION'] > df['INDICE_ROTACION'].median())\n",
        ").astype(int)\n",
        "\n",
        "\n",
        "# Revisar primeras filas\n",
        "print(df[['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION', 'EFICIENCIA']].head())\n",
        "\n",
        "# Contar cuántos 1 y 0 hay\n",
        "Distribucion_Clases = df['EFICIENCIA'].value_counts()\n",
        "Proporcion_Clases = df['EFICIENCIA'].value_counts(normalize=True) * 100\n",
        "\n",
        "print(\"\\nDistribución de Clases:\")\n",
        "print(Distribucion_Clases)\n",
        "\n",
        "print(\"\\nProporción de Clases:\")\n",
        "print(Proporcion_Clases)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHbqwCMp2XLZ"
      },
      "source": [
        "## **Balanceo**\n",
        "\n",
        "-Se utilizó SMOTE porque el conjunto de datos presenta un desbalance de clases (73%-27%) entre hospitales eficientes y no eficientes. Esta técnica genera nuevos ejemplos sintéticos de la clase minoritaria a partir de sus vecinos más cercanos, lo que permite equilibrar las clases sin eliminar información y mejorar el rendimiento de los modelos de clasificación, especialmente con variables numéricas continuas como las de este caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhIpTJsm2i1f",
        "outputId": "7917118c-6d92-4355-a692-5d497fe95938"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = df[['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']]\n",
        "y = df['EFICIENCIA']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "print(y.value_counts())\n",
        "print(y_train_res.value_counts())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qx-Q5J32ZxRI"
      },
      "source": [
        "## Tipo de datos de cada columna\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uc_eqoDr3Wn",
        "outputId": "19c8258b-d81b-40d4-d431-efe790ecfcd6"
      },
      "outputs": [],
      "source": [
        "print(df.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zJApbmrLD7I"
      },
      "outputs": [],
      "source": [
        "df_numerico = df.select_dtypes(include=['number'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JwBPbS1UeAF"
      },
      "source": [
        "## **Medidas Descriptivas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdEuDGLgUkmg",
        "outputId": "995d1209-0a89-4682-99c4-0380ba2c6d59"
      },
      "outputs": [],
      "source": [
        "descripcion_estadistica = df_numerico.describe()\n",
        "print(descripcion_estadistica)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teenH7MXuWcJ"
      },
      "source": [
        "## **Media**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8s2Ga3ruWcK",
        "outputId": "9b63c9f8-ccf3-47dc-cd0b-d9635860768d"
      },
      "outputs": [],
      "source": [
        "media = df_numerico.mean()\n",
        "print(f\"Media:\\n{media}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo5VLJP3n2p3"
      },
      "source": [
        "## **Medianas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2pKaUuLn2Vs",
        "outputId": "c4eea533-2222-49b9-fc8c-863e79160d4d"
      },
      "outputs": [],
      "source": [
        "mediana = df_numerico.median()\n",
        "print(f\"Mediana:\\n{mediana}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32dC6yGLoLN-"
      },
      "source": [
        "## **Moda**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FRi-XdIoVFV",
        "outputId": "f1d6cbca-7d51-4fa4-d6fb-4aada7a8cb14"
      },
      "outputs": [],
      "source": [
        "moda = df_numerico.mode().iloc[0]\n",
        "print(f\"Moda:\\n{moda}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSy7hpGoUyN"
      },
      "source": [
        "## **Desviacion Estandar**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8QfYZRn36ig",
        "outputId": "2b684e0a-d5dd-40ac-bb8b-83f16ffe8ce4"
      },
      "outputs": [],
      "source": [
        "desviacion_estandar = df_numerico.std()\n",
        "print(f\"Desviación Estándar:\\n{desviacion_estandar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rXNebrT71F6"
      },
      "source": [
        "## **Percentiles**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YoPRCVK71iD",
        "outputId": "e62b743d-e4a2-4b08-9851-8003c8d21da0"
      },
      "outputs": [],
      "source": [
        "percentiles = df_numerico.quantile(q=[0.1, 0.25, 0.5, 0.75, 0.9])\n",
        "print(f\"Percentiles:\\n{percentiles}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMXpI-AGO_oW",
        "outputId": "d5abc520-92b3-4d22-c426-092158e73e25"
      },
      "outputs": [],
      "source": [
        "# Detección de valores atípicos usando el rango intercuartílico\n",
        "\n",
        "Q1 = df_numerico.quantile(0.25)\n",
        "Q3 = df_numerico.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Identificar outliers\n",
        "outliers = ((df_numerico < (Q1 - 1.5 * IQR)) | (df_numerico > (Q3 + 1.5 * IQR))).sum()\n",
        "print(f\"Outliers detectados por columna:\\n{outliers}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s9XUjieEHuv"
      },
      "source": [
        "# **1. b. Visualización de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d74BUZDXWUDt",
        "outputId": "91c73f79-b355-43ff-f92e-345828a071e8"
      },
      "outputs": [],
      "source": [
        "# Indice ocupacional\n",
        "df['INDICE_OCUPACIONAL'] = pd.to_numeric(df['INDICE_OCUPACIONAL'], errors='coerce')\n",
        "\n",
        "plt.hist(df['INDICE_OCUPACIONAL'].dropna(), bins=10, alpha=0.7, color='steelblue')\n",
        "plt.xlabel('Índice Ocupacional')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución del Índice Ocupacional')\n",
        "plt.show()\n",
        "\n",
        "# Letalidad\n",
        "df['LETALIDAD'] = pd.to_numeric(df['LETALIDAD'], errors='coerce')\n",
        "\n",
        "plt.hist(df['LETALIDAD'].dropna(), bins=10, alpha=0.7, color='tomato')\n",
        "plt.xlabel('Letalidad')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución de la Letalidad')\n",
        "plt.show()\n",
        "\n",
        "# Indice de rotacion\n",
        "df['INDICE_ROTACION'] = pd.to_numeric(df['INDICE_ROTACION'], errors='coerce')\n",
        "\n",
        "plt.hist(df['INDICE_ROTACION'].dropna(), bins=10, alpha=0.7, color='seagreen')\n",
        "plt.xlabel('Índice de Rotación')\n",
        "plt.ylabel('Frecuencia')\n",
        "plt.title('Distribución del Índice de Rotación')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wSQeEA1AXv73",
        "outputId": "dbe1afc7-7bbe-4191-efec-4d25c617b449"
      },
      "outputs": [],
      "source": [
        "# Boxplot de Índice Ocupacional por eficiencia\n",
        "plt.boxplot(\n",
        "    [df.loc[df['EFICIENCIA'] == 0, 'INDICE_OCUPACIONAL'].dropna(),\n",
        "     df.loc[df['EFICIENCIA'] == 1, 'INDICE_OCUPACIONAL'].dropna()],\n",
        "    labels=['No Eficiente', 'Eficiente']\n",
        ")\n",
        "plt.ylabel('Índice Ocupacional')\n",
        "plt.title('Índice Ocupacional según Eficiencia')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot de Letalidad por eficiencia\n",
        "plt.boxplot(\n",
        "    [df.loc[df['EFICIENCIA'] == 0, 'LETALIDAD'].dropna(),\n",
        "     df.loc[df['EFICIENCIA'] == 1, 'LETALIDAD'].dropna()],\n",
        "    labels=['No Eficiente', 'Eficiente']\n",
        ")\n",
        "plt.ylabel('Letalidad')\n",
        "plt.title('Letalidad según Eficiencia')\n",
        "plt.show()\n",
        "\n",
        "# Boxplot de Índice de Rotación por eficiencia\n",
        "plt.boxplot(\n",
        "    [df.loc[df['EFICIENCIA'] == 0, 'INDICE_ROTACION'].dropna(),\n",
        "     df.loc[df['EFICIENCIA'] == 1, 'INDICE_ROTACION'].dropna()],\n",
        "    labels=['No Eficiente', 'Eficiente']\n",
        ")\n",
        "plt.ylabel('Índice de Rotación')\n",
        "plt.title('Índice de Rotación según Eficiencia')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "THFhI7oHYPXv",
        "outputId": "efeb9b3f-2d5e-4e6b-a4be-f35f0539d581"
      },
      "outputs": [],
      "source": [
        "# Asegurar tipo numérico\n",
        "df['INDICE_OCUPACIONAL'] = pd.to_numeric(df['INDICE_OCUPACIONAL'], errors='coerce')\n",
        "df['LETALIDAD'] = pd.to_numeric(df['LETALIDAD'], errors='coerce')\n",
        "\n",
        "# Separar por eficiencia\n",
        "eficiente = df[df['EFICIENCIA'] == 1]\n",
        "no_eficiente = df[df['EFICIENCIA'] == 0]\n",
        "\n",
        "plt.scatter(no_eficiente['INDICE_OCUPACIONAL'], no_eficiente['LETALIDAD'], alpha=0.5, label='No Eficiente', color='red')\n",
        "plt.scatter(eficiente['INDICE_OCUPACIONAL'], eficiente['LETALIDAD'], alpha=0.5, label='Eficiente', color='green')\n",
        "plt.xlabel('Índice Ocupacional')\n",
        "plt.ylabel('Letalidad')\n",
        "plt.title('Relación entre Índice Ocupacional y Letalidad según Eficiencia')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJWLe-gsdhk4"
      },
      "source": [
        "# **1. c. Exploración, limpieza y transformación de datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KiQiTpvDdoMh",
        "outputId": "e6a26774-0317-473c-8040-4db9e3a6849a"
      },
      "outputs": [],
      "source": [
        "# Mostrar las primeras filas del dataset\n",
        "print(\"Primeras filas del dataset:\")\n",
        "display(df.head())\n",
        "\n",
        "# Información general del dataset\n",
        "print(\"\\nInformación general del dataset:\")\n",
        "print(df.info())\n",
        "\n",
        "# Descripción estadística de las variables numéricas\n",
        "print(\"\\nDescripción estadística de las variables numéricas:\")\n",
        "display(df.describe().T)\n",
        "\n",
        "\n",
        "# Revisión de valores únicos en columnas categóricas\n",
        "print(\"\\nValores únicos en columnas categóricas:\")\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    print(f\"{col}: {df[col].nunique()} valores únicos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "4v1MA9nNeweT",
        "outputId": "e6724fb3-9938-4bd7-80e8-4feae2e00ff0"
      },
      "outputs": [],
      "source": [
        "# Contar valores nulos totales\n",
        "print(\"Valores nulos totales antes de limpiar:\")\n",
        "print(df.isnull().sum().sum())\n",
        "\n",
        "# Eliminar filas con valores nulos en variables relevantes\n",
        "variables_relevantes = ['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']\n",
        "df_limpio = df.dropna(subset=variables_relevantes)\n",
        "\n",
        "print(f\"\\nFilas originales: {len(df)}, Filas después de eliminar nulos: {len(df_limpio)}\")\n",
        "\n",
        "# Detección de valores atípicos usando el rango intercuartílico (IQR)\n",
        "for col in variables_relevantes:\n",
        "    Q1 = df_limpio[col].quantile(0.25)\n",
        "    Q3 = df_limpio[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    limite_inferior = Q1 - 1.5 * IQR\n",
        "    limite_superior = Q3 + 1.5 * IQR\n",
        "    df_limpio = df_limpio[(df_limpio[col] >= limite_inferior) & (df_limpio[col] <= limite_superior)]\n",
        "\n",
        "print(f\"Filas después de eliminar outliers: {len(df_limpio)}\")\n",
        "\n",
        "# Volver a calcular estadísticas con los datos limpios\n",
        "print(\"\\nDescripción estadística después de limpiar los datos:\")\n",
        "display(df_limpio.describe().T)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "9KVGBTThe8HF",
        "outputId": "ca39ad6c-714b-45e6-8b22-253e493e6f12"
      },
      "outputs": [],
      "source": [
        "# Copiar el dataset limpio\n",
        "df_transformado = df_limpio.copy()\n",
        "\n",
        "# Transformar variables categóricas en numéricas (Label Encoding)\n",
        "columnas_categoricas = ['GLOSA_SSS', 'AREA_FUNCIONAL', 'ESTABLECIMIENTO']\n",
        "le = LabelEncoder()\n",
        "for col in columnas_categoricas:\n",
        "    if col in df_transformado.columns:\n",
        "        df_transformado[col] = le.fit_transform(df_transformado[col].astype(str))\n",
        "\n",
        "print(\"\\nColumnas categóricas transformadas a numéricas correctamente.\")\n",
        "\n",
        "# Estandarización de variables numéricas\n",
        "columnas_numericas = ['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']\n",
        "scaler = StandardScaler()\n",
        "df_transformado[columnas_numericas] = scaler.fit_transform(df_transformado[columnas_numericas])\n",
        "\n",
        "print(\"Variables numéricas estandarizadas correctamente.\")\n",
        "\n",
        "# Verificar el resultado final\n",
        "print(\"\\nVista general de los datos transformados:\")\n",
        "display(df_transformado.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==========================\n",
        "# Punto 2 - Clasificación\n",
        "# ==========================\n",
        "\n",
        "# Preparar datos (usar df_transformado si existe)\n",
        "try:\n",
        "    df_used = df_transformado.copy()\n",
        "except NameError:\n",
        "    try:\n",
        "        df_used = df_limpio.copy()\n",
        "    except NameError:\n",
        "        df_used = df.copy()\n",
        "\n",
        "features = ['INDICE_OCUPACIONAL', 'LETALIDAD', 'INDICE_ROTACION']\n",
        "for f in features:\n",
        "    df_used[f] = pd.to_numeric(df_used[f], errors='coerce')\n",
        "\n",
        "# Eliminar filas con NaN en features o target\n",
        "df_used = df_used.dropna(subset=features + ['EFICIENCIA'])\n",
        "X = df_used[features]\n",
        "y = df_used['EFICIENCIA'].astype(int)\n",
        "\n",
        "# Revisar distribución de clases\n",
        "print('Distribución de clases (dataset):')\n",
        "print(y.value_counts())\n",
        "print('\\nProporción (%):')\n",
        "print(y.value_counts(normalize=True)*100)\n",
        "\n",
        "# Dividir en train/test con estratificación\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Aplicar SMOTE si hay desbalance > 70/30\n",
        "from imblearn.over_sampling import SMOTE\n",
        "imbalance_ratio = y.value_counts(normalize=True).max()\n",
        "apply_smote = imbalance_ratio > 0.7\n",
        "if apply_smote:\n",
        "    print('\\nDesbalance detectado (>70/30). Aplicando SMOTE sobre el conjunto de entrenamiento...')\n",
        "    sm = SMOTE(random_state=42)\n",
        "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
        "    print('Distribución después de SMOTE:')\n",
        "    print(y_train.value_counts())\n",
        "else:\n",
        "    print('\\nNo se aplicó SMOTE (balance aceptable).')\n",
        "\n",
        "# Modelos a evaluar\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "models = {\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
        "    'RandomForest': RandomForestClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Parámetros para GridSearch (ligero)\n",
        "param_grids = {\n",
        "    'KNN': {'n_neighbors': [3,5,7]},\n",
        "    'AdaBoost': {'n_estimators': [50,100]},\n",
        "    'RandomForest': {'n_estimators': [50,100], 'max_depth': [5, None]}\n",
        "}\n",
        "\n",
        "best_estimators = {}\n",
        "results = {}\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEntrenando y ajustando: {name}\")\n",
        "    grid = GridSearchCV(model, param_grids[name], scoring='roc_auc', cv=cv, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    best = grid.best_estimator_\n",
        "    best_estimators[name] = best\n",
        "    print(f\"Mejor params {name}: {grid.best_params_}\")\n",
        "    # Predicciones y métricas\n",
        "    y_pred = best.predict(X_test)\n",
        "    if hasattr(best, 'predict_proba'):\n",
        "        y_proba = best.predict_proba(X_test)[:,1]\n",
        "    else:\n",
        "        # algunos clasificadores usan decision_function\n",
        "        try:\n",
        "            y_proba = best.decision_function(X_test)\n",
        "        except Exception:\n",
        "            y_proba = None\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n",
        "    print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | ROC AUC: {auc:.4f} if available\")\n",
        "    print('\\nClassification report:')\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "    print('Confusion matrix:')\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    results[name] = {'model': best, 'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'auc': auc}\n",
        "\n",
        "# Curvas ROC comparadas\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc as calc_auc\n",
        "plt.figure(figsize=(8,6))\n",
        "for name, info in results.items():\n",
        "    model = info['model']\n",
        "    if hasattr(model, 'predict_proba') or hasattr(model, 'decision_function'):\n",
        "        if hasattr(model, 'predict_proba'):\n",
        "            prob = model.predict_proba(X_test)[:,1]\n",
        "        else:\n",
        "            prob = model.decision_function(X_test)\n",
        "        fpr, tpr, _ = roc_curve(y_test, prob)\n",
        "        roc_auc = calc_auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f\"{name} (AUC = {roc_auc:.3f})\")\n",
        "plt.plot([0,1],[0,1],'k--', alpha=0.6)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curves - Model comparison')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Importancia de variables (si RandomForest)\n",
        "if 'RandomForest' in best_estimators:\n",
        "    rf = best_estimators['RandomForest']\n",
        "    try:\n",
        "        importances = rf.feature_importances_\n",
        "        fi = pd.Series(importances, index=features).sort_values(ascending=False)\n",
        "        print('\\nImportancia de variables (RandomForest):')\n",
        "        print(fi)\n",
        "        fi.plot(kind='bar', title='Feature importance - RandomForest')\n",
        "        plt.show()\n",
        "    except Exception as e:\n",
        "        print('No se pudo obtener importancia de características:', e)\n",
        "\n",
        "# Guardar el mejor modelo por AUC\n",
        "best_by_auc = sorted([(k,v['auc']) for k,v in results.items() if v['auc'] is not None], key=lambda x: x[1] if x[1] is not None else -1, reverse=True)\n",
        "if best_by_auc:\n",
        "    best_name = best_by_auc[0][0]\n",
        "    print(f\"\\nMejor modelo por AUC: {best_name} (AUC={best_by_auc[0][1]:.3f})\")\n",
        "    best_model = results[best_name]['model']\n",
        "else:\n",
        "    # fallback por F1\n",
        "    best_name = sorted(results.items(), key=lambda x: x[1]['f1'], reverse=True)[0][0]\n",
        "    best_model = results[best_name]['model']\n",
        "    print(f\"\\nMejor modelo por F1: {best_name}\")\n",
        "\n",
        "print('\\nPunto 2 completado: modelos entrenados y métricas generadas.')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
